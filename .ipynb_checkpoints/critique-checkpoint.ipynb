{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from string import punctuation\n",
    "punctuation += \"—\"\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS-tagger\n",
    "\n",
    "Перед тем, как начать, нужно закачать один корпус:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_importer.import_corpus('latin_models_cltk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У таггера одна из самых неприятных проблем заключается в том, что он берет строку как есть, не меняя ее. Из-за этого любые имена собсвтенные не распознаются, если самому не написать его в нижнем регистре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Caesar', None)]\n",
      "[('caesar', 'N-S---MN-')]\n"
     ]
    }
   ],
   "source": [
    "from cltk.tag.pos import POSTag\n",
    "\n",
    "tagger = POSTag('latin')\n",
    "\n",
    "print(tagger.tag_ngram_123_backoff('Caesar'))\n",
    "print(tagger.tag_ngram_123_backoff('caesar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я достал из этого репозитория -- https://github.com/PerseusDL/treebank_data -- размеченные вручную тексты и положил их в папку perseus_tagged_corpus. Я записал в одну папку только словоформы, в другую -- только тэги, в третью -- только леммы (на потом)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_and_POStag_text(file):  \n",
    "    with open(f'perseus_tagged_corpus/{file}', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        soup = BeautifulSoup(text, 'xml')\n",
    "        sentences = []\n",
    "        POStag_sentences = []\n",
    "        lemmatized_sentences = []\n",
    "        for sent in soup.find_all('sentence'):\n",
    "            wordforms = []\n",
    "            POStags = []\n",
    "            lemmas = []\n",
    "            for w in sent.find_all('word'):\n",
    "                try:\n",
    "                    if w.attrs['postag'] and w.attrs['form'] not in punctuation:\n",
    "                        lemma = w.attrs['lemma']\n",
    "                        form = w.attrs['form']\n",
    "                        for punct in punctuation:\n",
    "                            form = form.replace(punct, '')\n",
    "                            lemma = lemma.replace(punct, '')\n",
    "                        wordforms.append(form)\n",
    "                        POStags.append(w.attrs['postag'])\n",
    "                        lemmas.append(lemma)\n",
    "                except:\n",
    "                    pass\n",
    "            sentences.append(wordforms)\n",
    "            POStag_sentences.append(POStags)\n",
    "            lemmatized_sentences.append(lemmas)\n",
    "    return (sentences, POStag_sentences, lemmatized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_perseus_files = os.listdir('perseus_tagged_corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phi0690.phi003.perseus-lat1.tb.xml',\n",
       " 'perseus-lattb.1248.1.xml',\n",
       " 'perseus-lattb.2219.1.xml',\n",
       " 'phi0631.phi001.perseus-lat1.tb.xml',\n",
       " 'phi0972.phi001.perseus-lat1.tb.xml',\n",
       " 'phi0474.phi013.perseus-lat1.tb.xml',\n",
       " 'phi0620.phi001.perseus-lat1.tb.xml',\n",
       " 'phi0448.phi001.perseus-lat1.tb.xml',\n",
       " 'phi0959.phi006.perseus-lat1.tb.xml',\n",
       " 'tlg0031.tlg027.perseus-lat1.tb.xml']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_perseus_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот сам процесс записывания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = {}\n",
    "POStag_texts = {}\n",
    "lemmas_texts = {}\n",
    "for file in tagged_perseus_files:\n",
    "    (sentences, POStag_sentences, lemmatized) = text_and_POStag_text(file)\n",
    "    texts[file] = sentences\n",
    "    POStag_texts[file] = POStag_sentences\n",
    "    lemmas_texts[file] = lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in texts.keys():\n",
    "    with open(f'perseus_text/{file[:-4]}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join([' '.join([w.lower() for w in sent]) for sent in texts[file]]))\n",
    "for file in POStag_texts.keys():\n",
    "    with open(f'perseus_tags/{file[:-4]}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join([' '.join(sent) for sent in POStag_texts[file]]))\n",
    "for file in lemmas_texts.keys():\n",
    "    with open(f'perseus_lemmas/{file[:-4]}.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join([' '.join([w.lower() for w in sent]) for sent in lemmas_texts[file]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция по проверке тэггера на точность. У cltk тэггера два. Один -- наивный байесовский классификатор, второй -- скрытая марковская модель (гораздо медленнее)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tagger_stats(POS_tagger, files):\n",
    "    percent_sum = 0\n",
    "    for file in files:\n",
    "        with open(f'perseus_text/{file[:-4]}.txt', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            spl_text = text.split()\n",
    "        with open(f'perseus_tags/{file[:-4]}.txt', encoding='utf-8') as f:\n",
    "            spl_tags = f.read().split()\n",
    "        cltk_tagged = []\n",
    "        for sent in text.split('\\n'):\n",
    "            tagged_sent = POS_tagger(sent)\n",
    "            cltk_tagged.extend(tagged_sent)\n",
    "        correct_tag_count = 0\n",
    "        total_tag_count = 0\n",
    "        wrong_tags = []\n",
    "        for i, (word, tag) in enumerate(cltk_tagged):\n",
    "                correct = False\n",
    "                if not tag or tag == 'Unk' and spl_tags[i] == 'u--------':\n",
    "                    correct = True\n",
    "                    correct_tag_count += 1\n",
    "                elif tag and tag.lower() == spl_tags[i]:\n",
    "                    correct = True\n",
    "                    correct_tag_count += 1\n",
    "                else:\n",
    "                    wrong_tags.append((word, tag))\n",
    "                if word != spl_text[i]:\n",
    "                    print(word + ' ' + spl_text[i])\n",
    "                #if spl_text[i] == 'que'\n",
    "                total_tag_count += 1\n",
    "        print(f'{file}:\\nТОЧНОСТЬ: {correct_tag_count/total_tag_count}\\n')\n",
    "        percent_sum += correct_tag_count/total_tag_count\n",
    "        pprint(Counter(wrong_tags).most_common(10))\n",
    "        print()\n",
    "    print(f'СРЕДНЯЯ ТОЧНОСТЬ: {percent_sum/len(files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примерные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi0690.phi003.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8983124188662917\n",
      "\n",
      "[(('quam', 'C--------'), 3),\n",
      " (('ardens', 'T-SPPAFN-'), 2),\n",
      " (('miseratus', 'T-SRPPMN-'), 2),\n",
      " (('cum', 'R--------'), 2),\n",
      " (('cui', 'P-S---MD-'), 2),\n",
      " (('te', 'P-S---MA-'), 2),\n",
      " (('tu', 'P-S---MN-'), 2),\n",
      " (('dictis', 'T-PRPPNB-'), 2),\n",
      " (('horrendas', 'T-PPGPFA-'), 2),\n",
      " (('involvens', 'T-SPPAMN-'), 2)]\n",
      "\n",
      "perseus-lattb.1248.1.xml:\n",
      "ТОЧНОСТЬ: 0.8077132981626342\n",
      "\n",
      "[(('inquit', 'V3SPIA---'), 53),\n",
      " (('quod', 'C--------'), 25),\n",
      " (('ne', 'D--------'), 17),\n",
      " (('qui', 'P-S---MN-'), 11),\n",
      " (('cum', 'R--------'), 11),\n",
      " (('haec', 'P-P---NA-'), 8),\n",
      " (('hoc', 'P-S---NA-'), 6),\n",
      " (('quae', 'P-S---FN-'), 6),\n",
      " (('suos', 'A-P---MA-'), 6),\n",
      " (('merito', 'N-S---NB-'), 6)]\n",
      "\n",
      "perseus-lattb.2219.1.xml:\n",
      "ТОЧНОСТЬ: 0.8430727023319616\n",
      "\n",
      "[(('etiam', 'D--------'), 43),\n",
      " (('ne', 'D--------'), 38),\n",
      " (('m', '---------'), 19),\n",
      " (('cum', 'C--------'), 16),\n",
      " (('se', 'P-S---MA-'), 13),\n",
      " (('p', '---------'), 11),\n",
      " (('quo', 'P-S---NB-'), 11),\n",
      " (('quam', 'C--------'), 9),\n",
      " (('quam', 'D--------'), 9),\n",
      " (('suo', 'A-S---NB-'), 9)]\n",
      "\n",
      "phi0631.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8961228968544257\n",
      "\n",
      "[(('ne', 'D--------'), 24),\n",
      " (('qui', 'P-S---MN-'), 20),\n",
      " (('ea', 'P-S---FB-'), 17),\n",
      " (('quae', 'P-S---FN-'), 14),\n",
      " (('quo', 'P-S---NB-'), 14),\n",
      " (('quod', 'C--------'), 11),\n",
      " (('conscripti', 'T-PRPPMV-'), 11),\n",
      " (('cum', 'C--------'), 10),\n",
      " (('quibus', 'P-P---MD-'), 9),\n",
      " (('post', 'R--------'), 9)]\n",
      "\n",
      "phi0972.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.9164221570196497\n",
      "\n",
      "[(('ne', 'D--------'), 44),\n",
      " (('cum', 'R--------'), 26),\n",
      " (('quod', 'C--------'), 21),\n",
      " (('quid', 'P-S---NN-'), 20),\n",
      " (('ut', 'C--------'), 14),\n",
      " (('c', 'C--------'), 13),\n",
      " (('et', 'C--------'), 11),\n",
      " (('qui', 'P-P---MN-'), 10),\n",
      " (('hoc', 'P-S---NA-'), 10),\n",
      " (('quae', 'P-S---FN-'), 9)]\n",
      "\n",
      "phi0474.phi013.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.9620207810820495\n",
      "\n",
      "[(('catilina', 'N-S---MN-'), 19),\n",
      " (('qui', 'P-S---MN-'), 13),\n",
      " (('cum', 'R--------'), 12),\n",
      " (('nihil', 'N-S---N--'), 11),\n",
      " (('quod', 'C--------'), 10),\n",
      " (('quid', 'P-S---NN-'), 8),\n",
      " (('quae', 'P-S---FN-'), 5),\n",
      " (('quod', 'P-S---NN-'), 5),\n",
      " (('ne', 'C--------'), 4),\n",
      " (('me', 'P-S---MA-'), 4)]\n",
      "\n",
      "phi0620.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8921501706484641\n",
      "\n",
      "[(('ne', 'D--------'), 29),\n",
      " (('tu', 'P-S---MN-'), 20),\n",
      " (('cynthia', 'N-S---FN-'), 13),\n",
      " (('quid', 'P-S---NN-'), 11),\n",
      " (('te', 'P-S---MA-'), 9),\n",
      " (('haec', 'P-P---NA-'), 6),\n",
      " (('quae', 'P-S---FN-'), 6),\n",
      " (('tibi', 'P-S---MD-'), 5),\n",
      " (('quid', 'P-S---NA-'), 4),\n",
      " (('ut', 'C--------'), 4)]\n",
      "\n",
      "phi0448.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.913232104121475\n",
      "\n",
      "[(('his', 'P-P---FB-'), 5),\n",
      " (('qui', 'P-S---MN-'), 4),\n",
      " (('quae', 'P-S---FN-'), 4),\n",
      " (('supra', 'R--------'), 2),\n",
      " (('se', 'P-S---MA-'), 2),\n",
      " (('cum', 'R--------'), 2),\n",
      " (('cohortatus', 'T-SRPPMN-'), 2),\n",
      " (('ne', 'D--------'), 2),\n",
      " (('cum', 'C--------'), 2),\n",
      " (('eo', 'P-S---MB-'), 2)]\n",
      "\n",
      "phi0959.phi006.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.905950991831972\n",
      "\n",
      "[(('ne', 'D--------'), 14),\n",
      " (('quod', 'C--------'), 9),\n",
      " (('ut', 'C--------'), 7),\n",
      " (('c', 'C--------'), 6),\n",
      " (('haec', 'P-P---NA-'), 5),\n",
      " (('te', 'P-S---MA-'), 5),\n",
      " (('quid', 'P-S---NA-'), 5),\n",
      " (('qua', 'P-S---FB-'), 4),\n",
      " (('tu', 'P-S---MN-'), 4),\n",
      " (('quae', 'P-S---FN-'), 3)]\n",
      "\n",
      "tlg0031.tlg027.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.9421379145788594\n",
      "\n",
      "[(('dicens', 'T-SPPAMN-'), 15),\n",
      " (('dicentes', 'T-PPPAMN-'), 11),\n",
      " (('datum', 'T-SRPPNN-'), 10),\n",
      " (('eius', 'P-S---FG-'), 9),\n",
      " (('dicentem', 'T-SPPAFA-'), 8),\n",
      " (('habentem', 'T-SPPAMA-'), 7),\n",
      " (('facta', 'T-SRPPFN-'), 7),\n",
      " (('factum', 'T-SRPPNN-'), 7),\n",
      " (('data', 'T-SRPPFN-'), 6),\n",
      " (('factus', 'T-SRPPMN-'), 6)]\n",
      "\n",
      "СРЕДНЯЯ ТОЧНОСТЬ: 0.8977135435497784\n"
     ]
    }
   ],
   "source": [
    "# примерная статистика tag_ngram_123_backoff\n",
    "# прокрутить вниз для средней точности.\n",
    "\n",
    "# для каждого анализируемого файла написан список самых частых ошибок тэггера -- слово и форма, которую он предложил.\n",
    "sentence_tagger_stats(tagger.tag_ngram_123_backoff, tagged_perseus_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi0690.phi003.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.7858070099524016\n",
      "\n",
      "[(('Aeneas', 'Unk'), 10),\n",
      " (('O', 'Unk'), 7),\n",
      " (('Sibyllae', 'Unk'), 5),\n",
      " (('Tum', 'Unk'), 5),\n",
      " (('Tu', 'Unk'), 4),\n",
      " (('At', 'Unk'), 3),\n",
      " (('Triviae', 'Unk'), 3),\n",
      " (('In', 'Unk'), 3),\n",
      " (('Phoebi', 'Unk'), 3),\n",
      " (('Non', 'Unk'), 3)]\n",
      "\n",
      "perseus-lattb.1248.1.xml:\n",
      "ТОЧНОСТЬ: 0.40887595489268824\n",
      "\n",
      "[(('inquit', 'V3SPIA---'), 53),\n",
      " (('Et', 'Unk'), 43),\n",
      " (('Qui', 'Unk'), 20),\n",
      " (('quod', 'C--------'), 17),\n",
      " (('Sed', 'Unk'), 16),\n",
      " (('Hoc', 'Unk'), 14),\n",
      " (('Quod', 'Unk'), 13),\n",
      " (('ne', 'D--------'), 13),\n",
      " (('Nec', 'Unk'), 13),\n",
      " (('Tunc', 'Unk'), 12)]\n",
      "\n",
      "perseus-lattb.2219.1.xml:\n",
      "ТОЧНОСТЬ: 0.4506308283049918\n",
      "\n",
      "[(('etiam', 'D--------'), 45),\n",
      " (('ne', 'D--------'), 30),\n",
      " (('uel', 'Unk'), 23),\n",
      " (('M', 'Unk'), 20),\n",
      " (('neque', 'Unk'), 15),\n",
      " (('se', 'P-S---MA-'), 12),\n",
      " (('quam', 'C--------'), 12),\n",
      " (('Antonio', 'Unk'), 11),\n",
      " (('gessit', 'Unk'), 11),\n",
      " (('C', 'Unk'), 10)]\n",
      "\n",
      "phi0631.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8592721287490855\n",
      "\n",
      "[(('Catilina', 'Unk'), 28),\n",
      " (('C', 'Unk'), 22),\n",
      " (('L', 'Unk'), 21),\n",
      " (('Sed', 'Unk'), 20),\n",
      " (('Catilinae', 'Unk'), 18),\n",
      " (('Q', 'Unk'), 17),\n",
      " (('M', 'Unk'), 16),\n",
      " (('ne', 'D--------'), 15),\n",
      " (('P', 'Unk'), 15),\n",
      " (('Romae', 'Unk'), 15)]\n",
      "\n",
      "phi0972.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8127500666844492\n",
      "\n",
      "[(('Trimalchio', 'Unk'), 74),\n",
      " (('Et', 'Unk'), 49),\n",
      " (('Quid', 'Unk'), 29),\n",
      " (('Itaque', 'Unk'), 26),\n",
      " (('Ne', 'Unk'), 25),\n",
      " (('Non', 'Unk'), 24),\n",
      " (('ne', 'D--------'), 23),\n",
      " (('Sed', 'Unk'), 22),\n",
      " (('Ego', 'Unk'), 20),\n",
      " (('Nam', 'Unk'), 19)]\n",
      "\n",
      "phi0474.phi013.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.9426728771049803\n",
      "\n",
      "[(('Catilina', 'Unk'), 29),\n",
      " (('Catilinam', 'Unk'), 11),\n",
      " (('Quirites', 'Unk'), 10),\n",
      " (('L', 'Unk'), 8),\n",
      " (('cum', 'R--------'), 8),\n",
      " (('etiam', 'D--------'), 7),\n",
      " (('M', 'Unk'), 7),\n",
      " (('Catilinae', 'Unk'), 7),\n",
      " (('O', 'Unk'), 5),\n",
      " (('C', 'Unk'), 5)]\n",
      "\n",
      "phi0620.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8534698521046644\n",
      "\n",
      "[(('Cynthia', 'Unk'), 29),\n",
      " (('ne', 'D--------'), 18),\n",
      " (('Amor', 'Unk'), 16),\n",
      " (('Galle', 'Unk'), 8),\n",
      " (('quid', 'P-S---NA-'), 5),\n",
      " (('tu', 'P-S---MN-'), 5),\n",
      " (('Tulle', 'Unk'), 4),\n",
      " (('a', 'R--------'), 4),\n",
      " (('Tu', 'Unk'), 4),\n",
      " (('et', 'C--------'), 4)]\n",
      "\n",
      "phi0448.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8214027476500362\n",
      "\n",
      "[(('Caesar', 'Unk'), 12),\n",
      " (('Gallia', 'Unk'), 6),\n",
      " (('Belgas', 'Unk'), 4),\n",
      " (('His', 'Unk'), 4),\n",
      " (('Cum', 'Unk'), 3),\n",
      " (('qui', 'P-S---MN-'), 3),\n",
      " (('Romani', 'Unk'), 3),\n",
      " (('Q', 'Unk'), 3),\n",
      " (('Belgis', 'Unk'), 3),\n",
      " (('Remis', 'Unk'), 3)]\n",
      "\n",
      "phi0959.phi006.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8350058343057176\n",
      "\n",
      "[(('Ne', 'Unk'), 9),\n",
      " (('ne', 'D--------'), 7),\n",
      " (('c', 'C--------'), 6),\n",
      " (('Non', 'Unk'), 5),\n",
      " (('Ut', 'Unk'), 5),\n",
      " (('Iove', 'Unk'), 4),\n",
      " (('Hic', 'Unk'), 4),\n",
      " (('Iuppiter', 'Unk'), 4),\n",
      " (('Quem', 'Unk'), 4),\n",
      " (('quid', 'P-S---NA-'), 4)]\n",
      "\n",
      "tlg0031.tlg027.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.9098067287043665\n",
      "\n",
      "[(('Dei', 'Unk'), 48),\n",
      " (('Deus', 'Unk'), 22),\n",
      " (('Deo', 'Unk'), 17),\n",
      " (('dicens', 'T-SPPAMN-'), 15),\n",
      " (('Iesu', 'Unk'), 13),\n",
      " (('dicentes', 'T-PPPAMN-'), 12),\n",
      " (('Deum', 'Unk'), 11),\n",
      " (('datum', 'T-SRPPNN-'), 10),\n",
      " (('Dominus', 'Unk'), 9),\n",
      " (('Spiritus', 'Unk'), 9)]\n",
      "\n",
      "СРЕДНЯЯ ТОЧНОСТЬ: 0.7679694028453382\n"
     ]
    }
   ],
   "source": [
    "# примерная статистика tag_tnt\n",
    "# прокрутить вниз для средней точности.\n",
    "# сейчас конкретно эта статистика не очень хорошая, т.к. анализировались\n",
    "# файлы, где имена собственные писались с большой буквы. в следующем коммите\n",
    "# это исправлю.\n",
    "sentence_tagger_stats(tagger.tag_tnt, tagged_perseus_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Макронайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.prosody.latin.macronizer import Macronizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "macrons = {\"ā\": \"a\",\n",
    "           \"ē\": \"e\",\n",
    "           \"ī\": \"i\",\n",
    "           \"ō\": \"o\",\n",
    "           \"ū\": \"u\",\n",
    "           \"Ā\": \"a\",\n",
    "           \"Ē\": \"e\",\n",
    "           \"Ī\": \"i\",\n",
    "           \"Ō\": \"o\",\n",
    "           \"Ū\": \"u\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "macronizer = Macronizer('tag_ngram_123_backoff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я взял довольно короткий текст, но и на нем видно, где макронайзер в основном ошибается.\n",
    "\n",
    "Если вы знаете, где найти хороший электронный архив латинских текстов, где отмечены долготы, буду благодарен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aeneid_text_premacronized = \"\"\"Arma virumque canō, Trōiae quī prīmus ab ōrīs\n",
    "Ītaliam, fātō profugus, Lāvīniaque vēnit\n",
    "lītora, multum ille et terrīs iactātus et altō\n",
    "vī superum saevae memorem Iūnōnis ob īram;\n",
    "multa quoque et bellō passūs, dum conderet urbem,\n",
    "inferretque deōs Latiō, genus unde Latīnum,\n",
    "Albānīque patrēs, atque altae moenia Rōmae.\n",
    "Mūsa, mihī causās memorā, quō nūmine laesō,\n",
    "quidve dolēns, rēgīna deum tot volvere cāsūs\n",
    "īnsīgnem pietāte virum, tot adīre labōrēs\n",
    "impulerit. Tantaene animīs caelestibus īrae?\n",
    "Urbs antīqua fuit, Tyriī tenuēre colōnī,\n",
    "Karthāgō, Ītaliam contrā Tiberīnaque longē\n",
    "ōstia, dīves opum studiīsque asperrima bellī,\n",
    "quam Iūnō fertur terrīs magis omnibus ūnam\n",
    "posthabitā coluisse Samō; hīc illius arma,\n",
    "hīc currus fuit; hōc rēgnum dea gentibus esse,\n",
    "sī quā Fāta sinant, iam tum tenditque fovetque.\n",
    "Prōgeniem sed enim Trōiānō ā sanguine dūcī\n",
    "audierat, Tyriās olim quae verteret arcēs;\n",
    "hinc populum lātē regem bellōque superbum\n",
    "ventūrum excidiō Libyae: sīc volvere Parcās.\n",
    "Id metuēns, veterisque memor Sāturnia bellī,\n",
    "prīma quod ad Trōiam prō cārīs gesserat Argīs—\n",
    "necdum etiam causae īrārum saevīque dolōrēs\n",
    "exciderant animō: manet altā mente repostum\n",
    "iūdicium Paridis sprētaeque iniūria fōrmae,\n",
    "et genus invīsum, et raptī Ganymēdis honōrēs.\n",
    "Hīs accēnsa super, iactātōs aequore tōtō\n",
    "Trōas, rēliquiās Danaum atque immītis Achillī,\n",
    "arcēbat longē Latiō, multōsque per annōs\n",
    "errābant, āctī Fātīs, maria omnia circum.\n",
    "Tantae mōlis erat Rōmānam condere gentem!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я удалил все макроны из текста и попросил макронизатор все расставить самому."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demacronize(text):\n",
    "    for macron in macrons.keys():\n",
    "        text = text.replace(macron, macrons[macron])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aeneid_text = demacronize(Aeneid_text_premacronized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Aeneid_text_premacronized_modified = \"\"\n",
    "for symbol in Aeneid_text_premacronized:\n",
    "    if symbol.upper() == symbol and symbol in macrons.keys():\n",
    "        Aeneid_text_premacronized_modified += macrons[symbol]+\"_\"\n",
    "    elif symbol in punctuation:\n",
    "        Aeneid_text_premacronized_modified += \" \"+symbol\n",
    "    elif symbol == \"\\n\":\n",
    "        Aeneid_text_premacronized_modified += \" \"\n",
    "    else:\n",
    "        Aeneid_text_premacronized_modified += symbol\n",
    "Aeneid_text_premacronized_modified = Aeneid_text_premacronized_modified.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(маленькие функции for convenience, не важны)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_from_letter_index(i, text):\n",
    "    word = \"\"\n",
    "    left = \"\"\n",
    "    right = \"\"\n",
    "    for symbol in text[i-1::-1]:\n",
    "        if symbol not in \" \\n\":\n",
    "            left += symbol\n",
    "        else:\n",
    "            break\n",
    "    for symbol in text[i+1:]:\n",
    "        if symbol not in \" \\n\":\n",
    "            right += symbol\n",
    "        else:\n",
    "            break\n",
    "    word = left[::-1]+text[i]+right\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vowel_count_latin(text):\n",
    "    vowel_count = 0\n",
    "    for symbol in text:\n",
    "        if symbol.lower() in \"aeiouāēīōū\":\n",
    "            vowel_count += 1\n",
    "    return vowel_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примерные результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cano canō\n",
      "trojae trōiae\n",
      "fato fātō\n",
      "fato fātō\n",
      "laviniaque lāvīniaque\n",
      "laviniaque lāvīniaque\n",
      "venit vēnit\n",
      "iactatus iactātus\n",
      "lātiō latiō\n",
      "latinum latīnum\n",
      "albanique albānīque\n",
      "albanique albānīque\n",
      "musa mūsa\n",
      "mihi mihī\n",
      "memora memorā\n",
      "laeso laesō\n",
      "insignem īnsīgnem\n",
      "insignem īnsīgnem\n",
      "tyrii tyriī\n",
      "karthago karthāgō\n",
      "karthago karthāgō\n",
      "tiberinaque tiberīnaque\n",
      "studiisque studiīsque\n",
      "posthabita posthabitā\n",
      "samo samō\n",
      "hic hīc\n",
      "illīus illius\n",
      "hic hīc\n",
      "currūs currus\n",
      "hoc hōc\n",
      "qua quā\n",
      "progeniem prōgeniem\n",
      "troiano trōiānō\n",
      "troiano trōiānō\n",
      "troiano trōiānō\n",
      "tyrias tyriās\n",
      "ōlim olim\n",
      "rēgem regem\n",
      "belloque bellōque\n",
      "excidio excidiō\n",
      "parcas parcās\n",
      "troiam trōiam\n",
      "caris cārīs\n",
      "caris cārīs\n",
      "argis argīs\n",
      "irarum īrārum\n",
      "irarum īrārum\n",
      "saevique saevīque\n",
      "alta altā\n",
      "spretaeque sprētaeque\n",
      "rapti raptī\n",
      "ganymedis ganymēdis\n",
      "iactatos iactātōs\n",
      "iactatos iactātōs\n",
      "totō tōtō\n",
      "troas trōas\n",
      "reliquiās rēliquiās\n",
      "immitis immītis\n",
      "arcebat arcēbat\n",
      "lātiō latiō\n",
      "multosque multōsque\n",
      "errabant errābant\n",
      "acti āctī\n",
      "acti āctī\n",
      "molis mōlis\n"
     ]
    }
   ],
   "source": [
    "# слова, в которых макронизатор что-то сделал неправильно\n",
    "wrong_vowel_count = 0\n",
    "for i, symbol in enumerate(macronizer.macronize_text(Aeneid_text)):\n",
    "    if symbol.lower() in \"aeiouāēīōū\" and symbol != Aeneid_text_premacronized_modified[i]:\n",
    "        print(word_from_letter_index(i, macronizer.macronize_text(Aeneid_text))+\" \"+word_from_letter_index(i, Aeneid_text_premacronized_modified))\n",
    "        wrong_vowel_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11565836298932385"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# такой процент гласных не угадывает макронайзер\n",
    "wrong_vowel_count / vowel_count_latin(Aeneid_text_premacronized_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clausulae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltk.prosody.latin.scanner import Scansion\n",
    "from cltk.prosody.latin.clausulae_analysis import Clausulae\n",
    "s = Scansion()\n",
    "c = Clausulae()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я посмотрел, хорошо ли он определяет клаузулы, взяв в пример несколько клаузул из Цицерона.\n",
    "\n",
    "Если в фразе уже проставлены макроны, то, естественно, все клаузулы угадываются. Но проблема в том, что для того, что он определил клаузулу, нужно, чтобы после нее стояла точка (даже вопросительный и восклицательный знак не распознаются)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "with open('Clausulae/clausulae.tsv', encoding='utf-8') as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    for line in tsvreader:\n",
    "        supposed_prosody = s.scan_text(line[0])\n",
    "        real_prosody = line[1].replace(\" \", \"\").replace(\"|\", \"\")\n",
    "        print(supposed_prosody[0].replace(\"x\", \"-\").endswith(real_prosody)\n",
    "            or supposed_prosody[0].replace(\"x\", \"u\").endswith(real_prosody))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заодно я посмотрел, как хорошо работает анализ клауз, если провести его через их же макронайзер. Как можно увидеть, плохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "with open('Clausulae/clausulae.tsv', encoding='utf-8') as tsvfile:\n",
    "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
    "    for line in tsvreader:\n",
    "        supposed_prosody = s.scan_text(macronizer.macronize_text(demacronize(line[0])))\n",
    "        real_prosody = line[1].replace(\" \", \"\").replace(\"|\", \"\")\n",
    "        print(supposed_prosody[0].replace(\"x\", \"-\").endswith(real_prosody)\n",
    "            or supposed_prosody[0].replace(\"x\", \"u\").endswith(real_prosody))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizer\n",
    "\n",
    "(функция, которая делает статистику)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_lemmatizer_stats(lemmatizer, files, numbered_lemmata_files, backoff=True):\n",
    "    percent_sum = 0\n",
    "    for file in files:\n",
    "        with open(f'perseus_text/{file[:-4]}.txt', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "            spl_text = text.split()\n",
    "        with open(f'perseus_lemmas/{file[:-4]}.txt', encoding='utf-8') as f:\n",
    "            spl_lemmas = f.read().split()\n",
    "        cltk_lemmas = []\n",
    "        for sent in text.split('\\n'):\n",
    "            if backoff:\n",
    "                lemmatized_sent = lemmatizer(sent.split())\n",
    "            else:\n",
    "                lemmatized_sent = []\n",
    "                for i, lemma in enumerate(lemmatizer(sent.split())):\n",
    "                    lemmatized_sent.append((sent.split()[i], lemma))\n",
    "            cltk_lemmas.extend(lemmatized_sent)\n",
    "        correct_lemma_count = 0\n",
    "        total_lemma_count = 0\n",
    "        wrong_lemmas = []\n",
    "        for i, (word, lemma) in enumerate(cltk_lemmas):\n",
    "                correct = False\n",
    "                if file in numbered_lemmata_files:\n",
    "                    if lemma[-1] not in '12345':\n",
    "                        lemma = lemma + '1'\n",
    "                else:\n",
    "                    if lemma == 'sum':\n",
    "                        lemma = 'sum1'\n",
    "                    elif lemma in ['cum2', 'cum1']:\n",
    "                        lemma = 'cum'\n",
    "                if lemma and lemma.lower() == spl_lemmas[i].lower():\n",
    "                    correct = True\n",
    "                    correct_lemma_count += 1\n",
    "                else:\n",
    "                    wrong_lemmas.append((word, lemma))\n",
    "                if word != spl_text[i]:\n",
    "                    print(word + ' ' + spl_text[i])\n",
    "                total_lemma_count += 1\n",
    "        print(f'{file}:\\nТОЧНОСТЬ: {correct_lemma_count/total_lemma_count}\\n')\n",
    "        percent_sum += correct_lemma_count/total_lemma_count\n",
    "        pprint(Counter(wrong_lemmas).most_common(10))\n",
    "        print()\n",
    "    print(f'СРЕДНЯЯ ТОЧНОСТЬ: {percent_sum/len(files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(тексты, где все леммы отмечены цифрой в конце (sum1 и т.д.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbered = ['phi0690.phi003.perseus-lat1.tb.xml',\n",
    " 'phi0631.phi001.perseus-lat1.tb.xml',\n",
    " 'phi0972.phi001.perseus-lat1.tb.xml',\n",
    " 'phi0474.phi013.perseus-lat1.tb.xml',\n",
    " 'phi0620.phi001.perseus-lat1.tb.xml',\n",
    " 'phi0448.phi001.perseus-lat1.tb.xml',\n",
    " 'phi0959.phi006.perseus-lat1.tb.xml',\n",
    " 'tlg0031.tlg027.perseus-lat1.tb.xml']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статистика для BackoffLatinLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi0690.phi003.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8645607961921247\n",
      "\n",
      "[(('c', '-que1'), 10),\n",
      " (('quam', 'quam1'), 7),\n",
      " (('super', 'super1'), 6),\n",
      " (('iam', 'iam1'), 6),\n",
      " (('cum', 'cum2'), 5),\n",
      " (('ferarum', 'ferus1'), 3),\n",
      " (('Talibus', 'Tal1'), 3),\n",
      " (('ossa', 'os1'), 3),\n",
      " (('litora', 'litus1'), 2),\n",
      " (('labor', 'labor1'), 2)]\n",
      "\n",
      "perseus-lattb.1248.1.xml:\n",
      "ТОЧНОСТЬ: 0.750045479352374\n",
      "\n",
      "[(('quod', 'qui'), 34),\n",
      " (('qui', 'qui'), 26),\n",
      " (('Qui', 'Qui'), 20),\n",
      " (('quae', 'qui'), 18),\n",
      " (('ne', 'ne'), 17),\n",
      " (('Hoc', 'Hoc'), 14),\n",
      " (('Nec', 'Nec'), 13),\n",
      " (('quis', 'quis'), 11),\n",
      " (('Quod', 'Quod'), 10),\n",
      " (('genus', 'genus'), 9)]\n",
      "\n",
      "perseus-lattb.2219.1.xml:\n",
      "ТОЧНОСТЬ: 0.7788751714677641\n",
      "\n",
      "[(('ne', 'ne'), 39),\n",
      " (('sed', 'sed'), 35),\n",
      " (('quod', 'qui'), 27),\n",
      " (('pro', 'pro'), 26),\n",
      " (('qui', 'qui'), 20),\n",
      " (('M', 'M'), 20),\n",
      " (('uel', 'uel'), 20),\n",
      " (('quibus', 'qui'), 18),\n",
      " (('e', 'e'), 14),\n",
      " (('quo', 'quo'), 12)]\n",
      "\n",
      "phi0631.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8861558156547183\n",
      "\n",
      "[(('cum', 'cum2'), 60),\n",
      " (('quod', 'qui1'), 33),\n",
      " (('quom', 'cum2'), 25),\n",
      " (('alia', 'alius1'), 18),\n",
      " (('alii', 'alius1'), 17),\n",
      " (('omnia', 'omnis1'), 17),\n",
      " (('quam', 'quam1'), 15),\n",
      " (('minus', 'paruus1'), 14),\n",
      " (('eo', 'is1'), 14),\n",
      " (('exercitu', 'exercitus1'), 14)]\n",
      "\n",
      "phi0972.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8380012447763848\n",
      "\n",
      "[(('cum', 'cum2'), 89),\n",
      " (('c', '-que1'), 47),\n",
      " (('iam', 'iam1'), 45),\n",
      " (('super', 'super1'), 34),\n",
      " (('Quid', 'Quid1'), 27),\n",
      " (('Itaque', 'Itaque1'), 26),\n",
      " (('iussit', 'iubeo1'), 19),\n",
      " (('quid', 'quis1'), 18),\n",
      " (('quod', 'qui1'), 16),\n",
      " (('servus', 'servus1'), 14)]\n",
      "\n",
      "phi0474.phi013.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.9020064493013257\n",
      "\n",
      "[(('cum', 'cum2'), 55),\n",
      " (('iam', 'iam1'), 54),\n",
      " (('quod', 'qui1'), 30),\n",
      " (('quam', 'quam1'), 11),\n",
      " (('quo', 'quo1'), 10),\n",
      " (('coniurationem', 'coniuratio1'), 5),\n",
      " (('vita', 'vito1'), 5),\n",
      " (('exercitum', 'exercitus1'), 5),\n",
      " (('dixi', 'dico1'), 4),\n",
      " (('omnium', 'omnis1'), 4)]\n",
      "\n",
      "phi0620.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.847098976109215\n",
      "\n",
      "[(('c', '-que1'), 41),\n",
      " (('ne', 'ne1'), 32),\n",
      " (('Cynthia', 'Cynthius1'), 29),\n",
      " (('cum', 'cum2'), 12),\n",
      " (('iam', 'iam1'), 8),\n",
      " (('qua', 'qui1'), 8),\n",
      " (('quod', 'qui1'), 8),\n",
      " (('quamvis', 'quivis1'), 8),\n",
      " (('Galle', 'Gallus1'), 8),\n",
      " (('seu', 'seu1'), 8)]\n",
      "\n",
      "phi0448.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.866232827187274\n",
      "\n",
      "[(('cum', 'cum2'), 17),\n",
      " (('quod', 'qui1'), 9),\n",
      " (('exercitum', 'exercitus1'), 5),\n",
      " (('Belgas', 'Belga1'), 4),\n",
      " (('His', 'His1'), 4),\n",
      " (('Cum', 'Cos2'), 3),\n",
      " (('exercitus', 'exercitus1'), 3),\n",
      " (('minus', 'paruus1'), 3),\n",
      " (('Belgis', 'Belga1'), 3),\n",
      " (('iam', 'iam1'), 3)]\n",
      "\n",
      "phi0959.phi006.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8707117852975496\n",
      "\n",
      "[(('c', '-que1'), 23),\n",
      " (('cum', 'cum2'), 14),\n",
      " (('nova', 'novo1'), 5),\n",
      " (('qua', 'qui1'), 5),\n",
      " (('quo', 'quo1'), 5),\n",
      " (('iam', 'iam1'), 5),\n",
      " (('quam', 'quam1'), 4),\n",
      " (('cetera', 'ceterus1'), 4),\n",
      " (('Quem', 'Quem1'), 4),\n",
      " (('coniunx', 'coniunx1'), 4)]\n",
      "\n",
      "tlg0031.tlg027.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.9169649248389405\n",
      "\n",
      "[(('super', 'super1'), 61),\n",
      " (('Dei', 'Dei1'), 48),\n",
      " (('cum', 'cum2'), 48),\n",
      " (('vocem', 'voco1'), 24),\n",
      " (('dicens', 'dico1'), 21),\n",
      " (('dicit', 'dico1'), 20),\n",
      " (('Deo', 'Deo1'), 17),\n",
      " (('dicentes', 'dico1'), 15),\n",
      " (('conspectu', 'conspectus1'), 13),\n",
      " (('dicentem', 'dico1'), 12)]\n",
      "\n",
      "СРЕДНЯЯ ТОЧНОСТЬ: 0.852065347017767\n"
     ]
    }
   ],
   "source": [
    "from cltk.lemmatize.latin.backoff import BackoffLatinLemmatizer\n",
    "lemmatizer = BackoffLatinLemmatizer()\n",
    "\n",
    "sentence_lemmatizer_stats(lemmatizer.lemmatize, tagged_perseus_files, numbered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Статистика для LemmaReplacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi0690.phi003.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.771960190393769\n",
      "\n",
      "[(('ne', 'neo1'), 13),\n",
      " (('est', 'edo1'), 12),\n",
      " (('Aeneas', 'aeneus1'), 10),\n",
      " (('c', 'c1'), 10),\n",
      " (('super', 'supo1'), 6),\n",
      " (('omnia', 'omne1'), 6),\n",
      " (('Sibyllae', 'Sibyllae1'), 5),\n",
      " (('regna', 'regno1'), 5),\n",
      " (('iter', 'ito1'), 5),\n",
      " (('alta', 'alo1'), 5)]\n",
      "\n",
      "perseus-lattb.1248.1.xml:\n",
      "ТОЧНОСТЬ: 0.8231762779698018\n",
      "\n",
      "[(('est', 'edo1'), 85),\n",
      " (('esse', 'edo1'), 23),\n",
      " (('ne', 'neo1'), 17),\n",
      " (('quis', 'queo'), 11),\n",
      " (('quod', 'qui1'), 10),\n",
      " (('quo', 'quis1'), 10),\n",
      " (('esset', 'edo1'), 7),\n",
      " (('vocem', 'voco'), 7),\n",
      " (('quam', 'qui1'), 7),\n",
      " (('canis', 'cano'), 7)]\n",
      "\n",
      "perseus-lattb.2219.1.xml:\n",
      "ТОЧНОСТЬ: 0.7469135802469136\n",
      "\n",
      "[(('est', 'edo1'), 45),\n",
      " (('ne', 'neo1'), 39),\n",
      " (('quam', 'qui1'), 36),\n",
      " (('sed', 'sed'), 35),\n",
      " (('quo', 'quis1'), 23),\n",
      " (('quod', 'qui1'), 23),\n",
      " (('M', 'M'), 20),\n",
      " (('esset', 'edo1'), 15),\n",
      " (('sine', 'sino'), 15),\n",
      " (('modo', 'modus'), 14)]\n",
      "\n",
      "phi0631.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.7532004389173372\n",
      "\n",
      "[(('ne', 'neo1'), 112),\n",
      " (('est', 'edo1'), 76),\n",
      " (('quam', 'qui1'), 56),\n",
      " (('res', 'reor1'), 44),\n",
      " (('omnia', 'omne1'), 33),\n",
      " (('quod', 'qui1'), 33),\n",
      " (('magis', 'magus2'), 31),\n",
      " (('eo', 'eo1'), 31),\n",
      " (('uti', 'uto1'), 31),\n",
      " (('ita', 'ito1'), 27)]\n",
      "\n",
      "phi0972.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.7765626389259358\n",
      "\n",
      "[(('est', 'edo1'), 131),\n",
      " (('ne', 'neo1'), 59),\n",
      " (('c', 'c1'), 47),\n",
      " (('esse', 'edo1'), 43),\n",
      " (('quam', 'qui1'), 38),\n",
      " (('super', 'supo1'), 34),\n",
      " (('omnia', 'omne1'), 27),\n",
      " (('Itaque', 'ito1'), 26),\n",
      " (('Ne', 'neo1'), 25),\n",
      " (('nisi', 'nitor1'), 19)]\n",
      "\n",
      "phi0474.phi013.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.802042278753135\n",
      "\n",
      "[(('est', 'edo1'), 54),\n",
      " (('esse', 'edo1'), 49),\n",
      " (('ne', 'neo1'), 37),\n",
      " (('quam', 'qui1'), 33),\n",
      " (('quod', 'qui1'), 30),\n",
      " (('quis', 'queo1'), 25),\n",
      " (('rei', 'redeo1'), 22),\n",
      " (('publicae', 'publica1'), 21),\n",
      " (('modo', 'modus1'), 17),\n",
      " (('quo', 'quis1'), 16)]\n",
      "\n",
      "phi0620.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.769283276450512\n",
      "\n",
      "[(('ne', 'neo1'), 61),\n",
      " (('c', 'c1'), 41),\n",
      " (('est', 'edo1'), 27),\n",
      " (('mea', 'meo1'), 21),\n",
      " (('Amor', 'amo1'), 16),\n",
      " (('modo', 'modus1'), 14),\n",
      " (('saepe', 'saepis1'), 14),\n",
      " (('quam', 'qui1'), 11),\n",
      " (('licet', 'liceo1'), 9),\n",
      " (('magis', 'magus2'), 8)]\n",
      "\n",
      "phi0448.phi001.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.7801879971077368\n",
      "\n",
      "[(('esse', 'edo1'), 11),\n",
      " (('ne', 'neo1'), 10),\n",
      " (('castra', 'castro1'), 10),\n",
      " (('quod', 'qui1'), 9),\n",
      " (('est', 'edo1'), 7),\n",
      " (('omnes', 'omnes1'), 6),\n",
      " (('eo', 'eo1'), 6),\n",
      " (('omnibus', 'omne1'), 6),\n",
      " (('exercitum', 'exerceo1'), 5),\n",
      " (('Belgas', 'Belgas1'), 4)]\n",
      "\n",
      "phi0959.phi006.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.7887981330221704\n",
      "\n",
      "[(('est', 'edo1'), 58),\n",
      " (('ne', 'neo1'), 25),\n",
      " (('c', 'c1'), 23),\n",
      " (('modo', 'modus1'), 11),\n",
      " (('Ne', 'neo1'), 9),\n",
      " (('caelo', 'caelo1'), 8),\n",
      " (('esse', 'edo1'), 7),\n",
      " (('unda', 'undo1'), 6),\n",
      " (('nova', 'novo1'), 5),\n",
      " (('tecta', 'tego1'), 5)]\n",
      "\n",
      "tlg0031.tlg027.perseus-lat1.tb.xml:\n",
      "ТОЧНОСТЬ: 0.8420424719637318\n",
      "\n",
      "[(('est', 'edo1'), 152),\n",
      " (('super', 'supo1'), 61),\n",
      " (('ne', 'neo1'), 47),\n",
      " (('caelo', 'caelo1'), 35),\n",
      " (('vocem', 'voco1'), 24),\n",
      " (('sua', 'suum1'), 17),\n",
      " (('suis', 'suo1'), 16),\n",
      " (('ore', 'aurum1'), 16),\n",
      " (('opera', 'opero1'), 16),\n",
      " (('suam', 'suo1'), 15)]\n",
      "\n",
      "СРЕДНЯЯ ТОЧНОСТЬ: 0.7854167283751042\n"
     ]
    }
   ],
   "source": [
    "from cltk.stem.lemma import LemmaReplacer\n",
    "lemmatizer = LemmaReplacer('latin')\n",
    "\n",
    "sentence_lemmatizer_stats(lemmatizer.lemmatize, tagged_perseus_files, numbered, backoff = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, LemmaReplacer значительно хуже, да еще и очень голодный (постоянно приписывает est к edo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "См. https://github.com/Migabaj/latin_perseus_word2vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
